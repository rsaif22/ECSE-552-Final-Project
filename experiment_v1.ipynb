{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of GAN algorithm:** https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "**Kaggle Dataset:** https://www.kaggle.com/datasets/chenghanpu/brain-tumor-mri-and-ct-scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on google colab, uncomment the following line\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "import gdown \n",
    "\n",
    "url = \"https://drive.google.com/drive/folders/1s5Y-JimbgWDvQy5XW8xt7HK1RerpPAmv?usp=drive_link\"\n",
    "gdown.download_folder(url, output=\".\" , quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "MRI_train = np.load('data/final_project/test_input.npy')\n",
    "CT_train = np.load('data/final_project/train_output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: visualize the data above the data points are 2D images of size: size 65536\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming MRI_train contains 2D images of size 256x256\n",
    "image_size = 256\n",
    "\n",
    "for i in range(5):\n",
    "  plt.imshow(MRI_train[i].reshape(image_size, image_size), cmap='gray')\n",
    "  plt.show()\n",
    "  plt.imshow(CT_train[i].reshape(image_size, image_size), cmap='gray')\n",
    "  plt.show()\n",
    "  print(CT_train[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**  \n",
    "Adversarial Loss (Discriminator Loss):\n",
    "\n",
    "Purpose: This loss measures how well the discriminators can distinguish between real and fake samples.\n",
    "Indicator: A decreasing adversarial loss indicates that the generators are creating more realistic images that fool the discriminators.\n",
    "\n",
    "Cycle Consistency Loss:\n",
    "\n",
    "Purpose: This loss ensures that the mappings from one domain to another are consistent.\n",
    "Indicator: A decreasing cycle consistency loss indicates that the generators are learning to generate images that are consistent when translated back and forth between the two domains.\n",
    "\n",
    "Identity Loss (Optional):\n",
    "\n",
    "Purpose: If included, identity loss ensures that the generators do not change the input image unnecessarily.\n",
    "Indicator: A low identity loss indicates that the generators are preserving the input image structure when it belongs to the target domain.\n",
    "\n",
    "Overall Generator Loss:\n",
    "\n",
    "Purpose: This is the sum of the adversarial loss, cycle consistency loss, and identity loss (if used).\n",
    "Indicator: Monitoring the overall generator loss provides an overview of how well the generators are performing across all aspects.\n",
    "\n",
    "Discriminator Loss: The discriminator's goal is to distinguish between real and fake samples effectively, which translates to maximizing its loss function. The loss will therefore increase in magnitude and become negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports for training:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gen_model import Generator\n",
    "from dis_model import Discriminator\n",
    "\n",
    "## Define generators and discriminators\n",
    "\n",
    "# MRI images and CT scan images are grayscale therefore our input_channel = 1 and output_channel = 1 (With this kaggle dataset)\n",
    "mri_channel = 1\n",
    "ct_channel = 1\n",
    "\n",
    "# Generators\n",
    "generator_mri2ct = Generator(1, 1)\n",
    "generator_ct2mri = Generator(ct_channel, mri_channel)\n",
    "\n",
    "# Discriminators\n",
    "discriminator_mri = Discriminator(mri_channel)\n",
    "discriminator_ct = Discriminator(ct_channel)\n",
    "\n",
    "# Define Optimizers *betas control the exponential decay rates*\n",
    "optimizer_gen = torch.optim.Adam(list(generator_mri2ct.parameters()) + list(generator_ct2mri.parameters()), lr=1e-4, betas=(0.5, 0.999))\n",
    "optimizer_dis_mri = torch.optim.Adam(list(discriminator_mri.parameters()) + list(discriminator_ct.parameters()), lr=1e-6, betas=(0.5, 0.999))\n",
    "optimizer_dis_ct = torch.optim.Adam(list(discriminator_mri.parameters()) + list(discriminator_ct.parameters()), lr=1e-6, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "# Training Loop parameters\n",
    "num_epochs = 10\n",
    "batch_size = 4  # Adjust this based on system's memory\n",
    "lambda_cycle = 10  # Adjust this value based on experimentation\n",
    "lambda_identity = 5  # If you use identity loss, adjust this as needed\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move models and tensors to GPU\n",
    "generator_mri2ct.to(device)\n",
    "generator_ct2mri.to(device)\n",
    "discriminator_mri.to(device)\n",
    "discriminator_ct.to(device)\n",
    "# Create data loader for training\n",
    "dataset = list(zip(MRI_train, CT_train))  # Combine MRI_train and CT_train\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion_cycle = nn.SmoothL1Loss()\n",
    "\n",
    "# Identity Loss\n",
    "use_identity_loss = False\n",
    "loss_identity_ct = \"NA\"\n",
    "loss_identity_mri = \"NA\"\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Set models to training mode\n",
    "    generator_mri2ct.train()\n",
    "    generator_ct2mri.train()\n",
    "    discriminator_mri.train()\n",
    "    discriminator_ct.train()\n",
    "\n",
    "    for i, (real_mri, real_ct) in enumerate(dataloader):\n",
    "        real_mri = real_mri.to(device)\n",
    "        real_ct = real_ct.to(device)\n",
    "\n",
    "        real_mri = real_mri.float().unsqueeze(0)\n",
    "        real_ct = real_ct.float().unsqueeze(0)\n",
    "\n",
    "\n",
    "        # Reshaping Tensor to match the generator input shape\n",
    "        real_mri = real_mri.permute(1, 0, 2, 3)\n",
    "        real_ct = real_ct.permute(1, 0, 2, 3)\n",
    "\n",
    "        # Generate fake images\n",
    "        fake_ct = generator_mri2ct(real_mri)\n",
    "        fake_mri = generator_ct2mri(real_ct)\n",
    "\n",
    "        ### Discriminator Training ###\n",
    "        optimizer_dis_mri.zero_grad()\n",
    "        optimizer_dis_ct.zero_grad()\n",
    "\n",
    "        # Compute discriminator losses for MRI and CT images\n",
    "        loss_dis_mri_real = discriminator_mri(real_mri).mean()\n",
    "        loss_dis_mri_fake = discriminator_mri(fake_mri.detach()).mean()\n",
    "        loss_dis_mri = loss_dis_mri_fake - loss_dis_mri_real\n",
    "\n",
    "        loss_dis_ct_real = discriminator_ct(real_ct).mean()\n",
    "        loss_dis_ct_fake = discriminator_ct(fake_ct.detach()).mean()\n",
    "        loss_dis_ct = loss_dis_ct_fake - loss_dis_ct_real\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_dis = (loss_dis_mri + loss_dis_ct) / 2\n",
    "\n",
    "        # Backpropagation and optimizer step for discriminator\n",
    "        loss_dis.backward()\n",
    "        optimizer_dis_mri.step()\n",
    "        optimizer_dis_ct.step()\n",
    "\n",
    "        ### Generator Training ###\n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        # Adversarial losses for generators\n",
    "        loss_gen_mri2ct_adv = -discriminator_ct(fake_ct).mean()\n",
    "        loss_gen_ct2mri_adv = -discriminator_mri(fake_mri).mean()\n",
    "\n",
    "        # Cycle consistency losses\n",
    "        reconstructed_mri = generator_ct2mri(fake_ct)\n",
    "        reconstructed_ct = generator_mri2ct(fake_mri)\n",
    "\n",
    "        loss_cycle_mri = criterion_cycle(reconstructed_mri, real_mri)\n",
    "        loss_cycle_ct = criterion_cycle(reconstructed_ct, real_ct)\n",
    "\n",
    "        # Identity losses (optional)\n",
    "        if use_identity_loss:\n",
    "            identity_mri = generator_ct2mri(real_mri)\n",
    "            identity_ct = generator_mri2ct(real_ct)\n",
    "\n",
    "            loss_identity_mri = criterion_identity(identity_mri, real_mri)\n",
    "            loss_identity_ct = criterion_identity(identity_ct, real_ct)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_gen = (loss_gen_mri2ct_adv + loss_gen_ct2mri_adv) + lambda_cycle * (loss_cycle_mri + loss_cycle_ct)\n",
    "        if use_identity_loss:\n",
    "            loss_gen += lambda_identity * (loss_identity_mri + loss_identity_ct)\n",
    "\n",
    "        # Backpropagation and optimizer step for generator\n",
    "        loss_gen.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Print loss statistics\n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D_MRI: %.4f Loss_D_CT: %.4f Loss_G_MRI2CT_adv: %.4f Loss_G_CT2MRI_adv: %.4f Loss_Cycle_MRI: %.4f Loss_Cycle_CT: %.4f' %\n",
    "                  (epoch, num_epochs, i, len(dataloader), loss_dis_mri.item(), loss_dis_ct.item(), loss_gen_mri2ct_adv.item(), loss_gen_ct2mri_adv.item(), loss_cycle_mri.item(), loss_cycle_ct.item()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
